{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS tagging using modified Viterbi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the Treebank tagged sentences\n",
    "nltk_data = list(nltk.corpus.treebank.tagged_sents(tagset='universal'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring The Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing out first three sentences to check the tuples of words and their corresponding POS tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('Pierre', 'NOUN'), ('Vinken', 'NOUN'), (',', '.'), ('61', 'NUM'), ('years', 'NOUN'), ('old', 'ADJ'), (',', '.'), ('will', 'VERB'), ('join', 'VERB'), ('the', 'DET'), ('board', 'NOUN'), ('as', 'ADP'), ('a', 'DET'), ('nonexecutive', 'ADJ'), ('director', 'NOUN'), ('Nov.', 'NOUN'), ('29', 'NUM'), ('.', '.')], [('Mr.', 'NOUN'), ('Vinken', 'NOUN'), ('is', 'VERB'), ('chairman', 'NOUN'), ('of', 'ADP'), ('Elsevier', 'NOUN'), ('N.V.', 'NOUN'), (',', '.'), ('the', 'DET'), ('Dutch', 'NOUN'), ('publishing', 'VERB'), ('group', 'NOUN'), ('.', '.')], [('Rudolph', 'NOUN'), ('Agnew', 'NOUN'), (',', '.'), ('55', 'NUM'), ('years', 'NOUN'), ('old', 'ADJ'), ('and', 'CONJ'), ('former', 'ADJ'), ('chairman', 'NOUN'), ('of', 'ADP'), ('Consolidated', 'NOUN'), ('Gold', 'NOUN'), ('Fields', 'NOUN'), ('PLC', 'NOUN'), (',', '.'), ('was', 'VERB'), ('named', 'VERB'), ('*-1', 'X'), ('a', 'DET'), ('nonexecutive', 'ADJ'), ('director', 'NOUN'), ('of', 'ADP'), ('this', 'DET'), ('British', 'ADJ'), ('industrial', 'ADJ'), ('conglomerate', 'NOUN'), ('.', '.')]]\n"
     ]
    }
   ],
   "source": [
    "print(nltk_data[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flattening out the sentences into tuple pairs of words and corresponding POS tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length Of Tagged Words:  100676\n",
      "First few pairs:  [('Pierre', 'NOUN'), ('Vinken', 'NOUN'), (',', '.'), ('61', 'NUM')]\n"
     ]
    }
   ],
   "source": [
    "tagged_words = [tup for sent in nltk_data for tup in sent]\n",
    "print(\"Length Of Tagged Words: \",len(tagged_words))\n",
    "print(\"First few pairs: \",tagged_words[:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the unique words and the unique POS tags in the corpora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_words(tagged_words = tagged_words):\n",
    "    \"\"\"\n",
    "    Generates unique words from given tagged tuples.\n",
    "    \n",
    "    @Author: Aryan Singh\n",
    "    \"\"\"\n",
    "    words = [tup[0] for tup in tagged_words]\n",
    "    unique_words = set(words)\n",
    "    return unique_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12408\n"
     ]
    }
   ],
   "source": [
    "unique_words = get_unique_words()\n",
    "print(len(unique_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Let's look at all the unique tags according to the corporus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_tags(tagged_words = tagged_words):\n",
    "    \"\"\"\n",
    "    Generates all unique tags from labelled tuples.\n",
    "    \n",
    "    @Author: Aryan Singh\n",
    "    \"\"\"\n",
    "    tags = [tup[1] for tup in tagged_words]\n",
    "    unique_tags = set(tags)\n",
    "    return unique_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ADP', 'CONJ', '.', 'ADV', 'NUM', 'X', 'VERB', 'PRON', 'DET', 'NOUN', 'PRT', 'ADJ'}\n"
     ]
    }
   ],
   "source": [
    "unique_tags = get_unique_tags()\n",
    "print(unique_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at most frequent POS tags and words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('NOUN', 28867),\n",
       " ('VERB', 13564),\n",
       " ('.', 11715),\n",
       " ('ADP', 9857),\n",
       " ('DET', 8725),\n",
       " ('X', 6613),\n",
       " ('ADJ', 6397),\n",
       " ('NUM', 3546),\n",
       " ('PRT', 3219),\n",
       " ('ADV', 3171),\n",
       " ('PRON', 2737),\n",
       " ('CONJ', 2265)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "tags = [tup[1] for tup in tagged_words]\n",
    "tag_counts = Counter(tags)\n",
    "tag_counts.most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a method to find the most common tag assigned to a particular word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_most_common_tag(word):\n",
    "    \"\"\"\n",
    "    Get the most common tag for a word. For basic unigram POS tagger\n",
    "    \n",
    "    @Author Aryan Singh\n",
    "    \"\"\"\n",
    "    tags = [tup[1] for tup in tagged_words if tup[0]==word]\n",
    "    ct = Counter(tags).most_common(1)\n",
    "    if not ct or ct==[]:\n",
    "        return 'UNKNOWN'\n",
    "    else:\n",
    "        return ct[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NOUN'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_most_common_tag('Pierre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tags_word_end(tagged_words, ending, tag):\n",
    "    \"\"\"\n",
    "    Method that takes in the ending and tag to find the\n",
    "    percentage of words with that tag and that particular ending.\n",
    "       \n",
    "    @Author Aryan Singh\n",
    "    \"\"\"\n",
    "    words_with_tag = [pair for pair in tagged_words if pair[1]==tag]\n",
    "    end_pos = [pair for pair in words_with_tag if pair[0].endswith(ending)]\n",
    "    return round((len(end_pos)*100.0/len(words_with_tag)),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic Analysis For Verbs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check percentage of verbs ending with ed and ing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.69"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_tags_word_end(tagged_words,'ed','VERB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.85"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_tags_word_end(tagged_words,'ing','VERB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check how many tags follow another tag**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_tag_followup(tags, tag1, tag2):\n",
    "    \"\"\"\n",
    "    Method that checks percentage of instances where\n",
    "    tag2 follows tag1 as compared to total number of occurences of tag1.\n",
    "    \n",
    "    @Author Aryan Singh\n",
    "    \"\"\"\n",
    "    words_with_tag = [tag for tag in tags if tag==tag1]\n",
    "    tags_t1_t2 = [(t, tags[i+1]) for i,t in enumerate(tags) if t==tag1 and tags[i+1]==tag2]\n",
    "    return round((len(tags_t1_t2)*100.0/len(words_with_tag)),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adjective followed by a noun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69.94"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_tag_followup(tags, 'ADJ', 'NOUN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So adjective is followed by a noun is almost 70% of the cases. This can be a good rule to find POS tags for unknown words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the vanilla Viterbi based POS tagger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purpose of building a Viterbi heuristic and HMM based POS tagger First we need to calculate the **transmission probabilities(p(next tag/prev tag))** and **emission probabilities(p(word/tag))**. Then we can calculate the **p(tag/word) = emission prob * transmission prob**. In transmission prob. only the previous tag metters fue to the Markovian assumption."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into train and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3718\n",
      "196\n",
      "[[('No', 'DET'), ('one', 'PRON'), ('speaks', 'VERB'), (',', '.'), ('and', 'CONJ'), ('the', 'DET'), ('snaking', 'VERB'), ('of', 'ADP'), ('the', 'DET'), ('ropes', 'NOUN'), ('seems', 'VERB'), ('*-1', 'X'), ('to', 'PRT'), ('make', 'VERB'), ('as', 'ADP'), ('much', 'ADJ'), ('sound', 'NOUN'), ('as', 'ADP'), ('the', 'DET'), ('bells', 'NOUN'), ('themselves', 'PRON'), ('*?*', 'X'), (',', '.'), ('*-2', 'X'), ('muffled', 'VERB'), ('*-3', 'X'), ('by', 'ADP'), ('the', 'DET'), ('ceiling', 'NOUN'), ('.', '.')], [('They', 'PRON'), ('fell', 'VERB'), ('into', 'ADP'), ('oblivion', 'NOUN'), ('after', 'ADP'), ('the', 'DET'), ('1929', 'NUM'), ('crash', 'NOUN'), ('.', '.')], [('It', 'PRON'), ('would', 'VERB'), ('contradict', 'VERB'), ('that', 'DET'), ('objective', 'NOUN'), ('if', 'ADP'), ('the', 'DET'), ('appropriations', 'NOUN'), ('clause', 'NOUN'), ('-LRB-', '.'), ('technically', 'ADV'), ('a', 'DET'), ('limitation', 'NOUN'), ('on', 'ADP'), ('legislative', 'ADJ'), ('power', 'NOUN'), ('-RRB-', '.'), ('could', 'VERB'), ('be', 'VERB'), ('read', 'VERB'), ('*-52', 'X'), ('as', 'ADP'), ('*-52', 'X'), ('placing', 'VERB'), ('the', 'DET'), ('president', 'NOUN'), ('on', 'ADP'), ('Congress', 'NOUN'), (\"'s\", 'PRT'), ('short', 'ADJ'), ('leash', 'NOUN'), (',', '.'), ('*-52', 'X'), ('making', 'VERB'), ('the', 'DET'), ('executive', 'NOUN'), ('consist', 'VERB'), ('of', 'ADP'), ('the', 'DET'), ('president', 'NOUN'), ('and', 'CONJ'), ('every', 'DET'), ('member', 'NOUN'), ('of', 'ADP'), ('Congress', 'NOUN'), ('.', '.')]]\n"
     ]
    }
   ],
   "source": [
    "# Splitting into train and test\n",
    "random.seed(1234)\n",
    "train_set, test_set = train_test_split(nltk_data,test_size=0.05)\n",
    "\n",
    "print(len(train_set))\n",
    "print(len(test_set))\n",
    "print(train_set[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95705"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting list of tagged words\n",
    "train_tagged_words = [tup for sent in train_set for tup in sent]\n",
    "len(train_tagged_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12086"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V = get_unique_words(tagged_words = train_tagged_words)\n",
    "len(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of tags\n",
    "T = get_unique_tags(tagged_words = train_tagged_words)\n",
    "len(T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emission Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = len(T)\n",
    "v = len(V)\n",
    "w_given_t = np.zeros((t, v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute word given tag: Emission Probability\n",
    "tag_dict = {}\n",
    "def word_given_tag(word, tag, train_bag = train_tagged_words):\n",
    "    \"\"\"\n",
    "    Calculate emssion probability of a word given a tag.\n",
    "    \n",
    "    @Author Aryan Singh\n",
    "    \"\"\"\n",
    "    tag_list = []\n",
    "    if(tag in tag_dict):\n",
    "        tag_list = tag_dict[tag]\n",
    "    else:\n",
    "        tag_list = [pair for pair in train_bag if pair[1]==tag]\n",
    "        tag_dict[tag] = tag_list\n",
    "    count_tag = len(tag_list)\n",
    "    w_given_tag_list = [pair[0] for pair in tag_list if pair[0]==word]\n",
    "    count_w_given_tag = len(w_given_tag_list)\n",
    "    return count_w_given_tag/count_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.004445176160684887\n"
     ]
    }
   ],
   "source": [
    "# Check for emission prob of large against Adjective\n",
    "print(word_given_tag('large', 'ADJ'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# Check for an unknown word\n",
    "print(word_given_tag('Android','NOUN')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transition Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t2_given_t1(t2, t1, train_bag = train_tagged_words):\n",
    "    \"\"\"\n",
    "    Compute tag given tag: tag2(t2) given tag1 (t1), i.e. Transition Probability\n",
    "    \n",
    "    @Author Aryan Singh\n",
    "    \"\"\"\n",
    "    tags = [pair[1] for pair in train_bag]\n",
    "    count_t1 = len([t for t in tags if t==t1])\n",
    "    count_t2_t1 = 0\n",
    "    for index in range(len(tags)-1):\n",
    "        if tags[index]==t1 and tags[index+1] == t2:\n",
    "            count_t2_t1 += 1\n",
    "    return count_t2_t1/count_t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6992097464603226\n"
     ]
    }
   ],
   "source": [
    "# Checking it once\n",
    "print(t2_given_t1(t2='NOUN', t1='ADJ'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check What percentage of tags appear at the start of sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22095528820254984\n",
      "0.08843598491650206\n",
      "0.06563117256239899\n"
     ]
    }
   ],
   "source": [
    "#Please note P(tag|start) is same as P(tag|'.')\n",
    "print(t2_given_t1('NOUN', '.'))\n",
    "print(t2_given_t1('VERB', '.'))\n",
    "print(t2_given_t1('PRON', '.'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transition Probability Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating t x t transition matrix of tags\n",
    "# each column is t2, each row is t1\n",
    "# thus M(i, j) represents P(tj given ti)\n",
    "\n",
    "tags_matrix = np.zeros((len(T), len(T)), dtype='float32')\n",
    "for i, t1 in enumerate(list(T)):\n",
    "    for j, t2 in enumerate(list(T)): \n",
    "        tags_matrix[i, j] = t2_given_t1(t2, t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CONJ</th>\n",
       "      <th>ADP</th>\n",
       "      <th>.</th>\n",
       "      <th>ADV</th>\n",
       "      <th>NUM</th>\n",
       "      <th>PRON</th>\n",
       "      <th>VERB</th>\n",
       "      <th>X</th>\n",
       "      <th>DET</th>\n",
       "      <th>NOUN</th>\n",
       "      <th>PRT</th>\n",
       "      <th>ADJ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CONJ</th>\n",
       "      <td>0.000464</td>\n",
       "      <td>0.051532</td>\n",
       "      <td>0.036676</td>\n",
       "      <td>0.055246</td>\n",
       "      <td>0.041783</td>\n",
       "      <td>0.058496</td>\n",
       "      <td>0.157846</td>\n",
       "      <td>0.008357</td>\n",
       "      <td>0.119777</td>\n",
       "      <td>0.349118</td>\n",
       "      <td>0.004178</td>\n",
       "      <td>0.116527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADP</th>\n",
       "      <td>0.000748</td>\n",
       "      <td>0.016893</td>\n",
       "      <td>0.040308</td>\n",
       "      <td>0.013151</td>\n",
       "      <td>0.061478</td>\n",
       "      <td>0.069496</td>\n",
       "      <td>0.008019</td>\n",
       "      <td>0.034748</td>\n",
       "      <td>0.325457</td>\n",
       "      <td>0.321608</td>\n",
       "      <td>0.001390</td>\n",
       "      <td>0.106704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>0.058179</td>\n",
       "      <td>0.090411</td>\n",
       "      <td>0.094092</td>\n",
       "      <td>0.053331</td>\n",
       "      <td>0.081792</td>\n",
       "      <td>0.065631</td>\n",
       "      <td>0.088436</td>\n",
       "      <td>0.027563</td>\n",
       "      <td>0.173011</td>\n",
       "      <td>0.220955</td>\n",
       "      <td>0.002334</td>\n",
       "      <td>0.044173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADV</th>\n",
       "      <td>0.007280</td>\n",
       "      <td>0.120119</td>\n",
       "      <td>0.135341</td>\n",
       "      <td>0.079087</td>\n",
       "      <td>0.030113</td>\n",
       "      <td>0.015222</td>\n",
       "      <td>0.343812</td>\n",
       "      <td>0.023163</td>\n",
       "      <td>0.069821</td>\n",
       "      <td>0.031105</td>\n",
       "      <td>0.013567</td>\n",
       "      <td>0.131370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NUM</th>\n",
       "      <td>0.013777</td>\n",
       "      <td>0.035040</td>\n",
       "      <td>0.113208</td>\n",
       "      <td>0.002396</td>\n",
       "      <td>0.185385</td>\n",
       "      <td>0.001198</td>\n",
       "      <td>0.018568</td>\n",
       "      <td>0.215633</td>\n",
       "      <td>0.003294</td>\n",
       "      <td>0.353699</td>\n",
       "      <td>0.024558</td>\n",
       "      <td>0.033243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          CONJ       ADP         .       ADV       NUM      PRON      VERB  \\\n",
       "CONJ  0.000464  0.051532  0.036676  0.055246  0.041783  0.058496  0.157846   \n",
       "ADP   0.000748  0.016893  0.040308  0.013151  0.061478  0.069496  0.008019   \n",
       ".     0.058179  0.090411  0.094092  0.053331  0.081792  0.065631  0.088436   \n",
       "ADV   0.007280  0.120119  0.135341  0.079087  0.030113  0.015222  0.343812   \n",
       "NUM   0.013777  0.035040  0.113208  0.002396  0.185385  0.001198  0.018568   \n",
       "\n",
       "             X       DET      NOUN       PRT       ADJ  \n",
       "CONJ  0.008357  0.119777  0.349118  0.004178  0.116527  \n",
       "ADP   0.034748  0.325457  0.321608  0.001390  0.106704  \n",
       ".     0.027563  0.173011  0.220955  0.002334  0.044173  \n",
       "ADV   0.023163  0.069821  0.031105  0.013567  0.131370  \n",
       "NUM   0.215633  0.003294  0.353699  0.024558  0.033243  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert the matrix to a df for better readability\n",
    "tags_df = pd.DataFrame(tags_matrix, columns = list(T), index=list(T))\n",
    "tags_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Heat Map Of Frequent Tags**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x864 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# frequent tags\n",
    "# filter the df to get P(t2, t1) > 0.5\n",
    "tags_frequent = tags_df[tags_df>0.5]\n",
    "plt.figure(figsize=(18, 12))\n",
    "sns.heatmap(tags_frequent,cmap = 'YlGnBu')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vanilla Viterbi based HMM method**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vanilla Viterbi Heuristic\n",
    "def Viterbi(words, train_bag = train_tagged_words):\n",
    "    state = []\n",
    "    T = list(set([pair[1] for pair in train_bag]))\n",
    "    # training tags\n",
    "    for key, word in enumerate(words):\n",
    "        #initialise list of probability column for a given observation\n",
    "        p = [] \n",
    "        for tag in T:\n",
    "            if key == 0:\n",
    "                transition_p = tags_df.loc['.', tag]\n",
    "            else:\n",
    "                transition_p = tags_df.loc[state[-1], tag]\n",
    "                \n",
    "            # compute emission and state probabilities\n",
    "            emission_p = word_given_tag(words[key], tag)\n",
    "            state_probability = emission_p * transition_p    \n",
    "            p.append(state_probability)\n",
    "            \n",
    "        pmax = max(p)\n",
    "        # getting state for which probability is maximum\n",
    "        state_max = T[p.index(pmax)] \n",
    "        state.append(state_max)\n",
    "    return list(zip(words, state))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solve the problem of unknown words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving Vanilla Viterbi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach 1: Considering transition probabilities as backoff for missing emission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vanilla Viterbi with transition as backoff for missing emissions\n",
    "def Viterbi_transition_back(words, train_bag = train_tagged_words):\n",
    "    state = []\n",
    "    T = list(set([pair[1] for pair in train_bag]))\n",
    "    # training tags\n",
    "    for key, word in enumerate(words):\n",
    "        #initialise list of probability column for a given observation\n",
    "        p = [] \n",
    "        trans = []\n",
    "        for tag in T:\n",
    "            if key == 0:\n",
    "                transition_p = tags_df.loc['.', tag]\n",
    "            else:\n",
    "                transition_p = tags_df.loc[state[-1], tag]\n",
    "                \n",
    "            # compute emission and state probabilities\n",
    "            emission_p = word_given_tag(words[key], tag)\n",
    "            state_probability = emission_p * transition_p    \n",
    "            p.append(state_probability)\n",
    "            trans.append(transition_p)\n",
    "        pmax = max(p)\n",
    "        tmax = max(trans)\n",
    "        # getting state for which probability is maximum\n",
    "        if pmax != 0:       \n",
    "            state_max = T[p.index(pmax)] \n",
    "            state.append(state_max)\n",
    "        else:\n",
    "            state_max = T[trans.index(tmax)] \n",
    "            state.append(state_max)            \n",
    "    return list(zip(words, state))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach 2: Considering lexicon and rule based tagger as backoff for missing emissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "regexp_tagger = nltk.RegexpTagger(\n",
    " [(r'^-?[0-9]+(.[0-9]+)?$', 'NUM'),   # cardinal numbers\n",
    "  (r'(The|the|A|a|An|an)$', 'DET'),   # articles\n",
    "  (r'.*able$', 'ADJ'),                # adjectives\n",
    "  (r'.*ness$', 'NOUN'),               # nouns formed from adjectives\n",
    "  (r'.*ly$', 'ADV'),                  # adverbs\n",
    "  (r'.*s$', 'NOUN'),                  # plural nouns\n",
    "  (r'.*ing$', 'VERB'),                # gerunds\n",
    "  (r'.*ed$', 'VERB'),                 # past tense verbs\n",
    "  (r'.*', 'NOUN')                     # nouns (default)\n",
    "])\n",
    "unigram_tagger = nltk.UnigramTagger(train_set,backoff=regexp_tagger)\n",
    "bigram_tagger = nltk.BigramTagger(train_set, backoff=unigram_tagger) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lexical_rule_tagger(word, tagger = bigram_tagger):\n",
    "    \"\"\"\n",
    "    Takes a word and retrieves the POS tag using rule based and regex\n",
    "    based tagger.\n",
    "    \n",
    "    @Author: Aryan Singh\n",
    "    \"\"\"\n",
    "    tag_tup = bigram_tagger.tag([word])\n",
    "    return tag_tup[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vanilla Viterbi with lexical tagger as backoff\n",
    "def Viterbi_lexical_rule_back(words, train_bag = train_tagged_words):\n",
    "    state = []\n",
    "    T = list(set([pair[1] for pair in train_bag]))\n",
    "    # training tags\n",
    "    for key, word in enumerate(words):\n",
    "        #initialise list of probability column for a given observation\n",
    "        p = [] \n",
    "        for tag in T:\n",
    "            if key == 0:\n",
    "                transition_p = tags_df.loc['.', tag]\n",
    "            else:\n",
    "                transition_p = tags_df.loc[state[-1], tag]\n",
    "                \n",
    "            # compute emission and state probabilities\n",
    "            emission_p = word_given_tag(words[key], tag)\n",
    "            state_probability = emission_p * transition_p    \n",
    "            p.append(state_probability)\n",
    "        pmax = max(p)\n",
    "        # getting state for which probability is maximum\n",
    "        if pmax != 0:       \n",
    "            state_max = T[p.index(pmax)] \n",
    "            state.append(state_max)\n",
    "        else:\n",
    "            state.append(lexical_rule_tagger(word))            \n",
    "    return list(zip(words, state))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the tagging accuracies of the modifications with the vanilla Viterbi algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_tagged_test = [tup for sent in test_set for tup in sent]\n",
    "test_words = [tup[0] for tup in actual_tagged_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tagging_accuracy(predicted_tagged_test, actual_tagged_test = actual_tagged_test):\n",
    "    \"\"\"\n",
    "    Method to determine tagging accuracy given predicted tagset and actual one.\n",
    "    \n",
    "    @Author Aryan Singh\n",
    "    \"\"\"\n",
    "    check = [i for i, j in zip(predicted_tagged_test, actual_tagged_test) if i == j]\n",
    "    accuracy = len(check)/len(predicted_tagged_test)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy for Vanila Viterbi Algorithm**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9050492858579763\n"
     ]
    }
   ],
   "source": [
    "predicted_tagged_test = Viterbi(test_words)\n",
    "accuracy = get_tagging_accuracy(predicted_tagged_test)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy for Viterbi Heuristic HMM with transition probabilities as backup for missing Emission probabilities**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.935827801247234\n"
     ]
    }
   ],
   "source": [
    "predicted_tagged_test = Viterbi_transition_back(test_words)\n",
    "accuracy = get_tagging_accuracy(predicted_tagged_test)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy for Viterbi Heuristic HMM with lexical and rule based tagger as backup for missing Emission probabilities**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9509153087909877\n"
     ]
    }
   ],
   "source": [
    "predicted_tagged_test = Viterbi_lexical_rule_back(test_words)\n",
    "accuracy = get_tagging_accuracy(predicted_tagged_test)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the tagging accuracies on the test dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's read in the sentences containing a lot of unseen words and compare the tag prediction of the three approaches. Using intution and knowledge of english grammar to see which wrongly predicted POS tags got corrected as the approaches evolved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Android is a mobile operating system developed by Google.',\n",
       " 'Android has been the best-selling OS worldwide on smartphones since 2011 and on tablets since 2013.',\n",
       " \"Google and Twitter made a deal in 2015 that gave Google access to Twitter's firehose.\",\n",
       " 'Twitter is an online news and social networking service on which users post and interact with messages known as tweets.',\n",
       " 'Before entering politics, Donald Trump was a domineering businessman and a television personality.',\n",
       " 'The 2018 FIFA World Cup is the 21st FIFA World Cup, an international football tournament contested once every four years.',\n",
       " 'This is the first World Cup to be held in Eastern Europe and the 11th time that it has been held in Europe.',\n",
       " 'Show me the cheapest round trips from Dallas to Atlanta',\n",
       " 'I would like to see flights from Denver to Philadelphia.',\n",
       " 'Show me the price of the flights leaving Atlanta at about 3 in the afternoon and arriving in San Francisco.',\n",
       " 'NASA invited social media users to experience the launch of ICESAT-2 Satellite.']"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "path = 'http://aryancodify.tech/wp-content/uploads/2018/10/Test_sentences.txt'\n",
    "f = requests.get(path)\n",
    "sentences = f.content.splitlines()\n",
    "sentences = map(lambda sen : sen.decode(\"utf-8\"),sentences)\n",
    "sentences = list(sentences)[:-3]\n",
    "sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the sentences, let's get the individual tokens, that were not present in our training dataset and check the accuracy for respective words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "token_lists = [word_tokenize(sentence) for sentence in sentences]\n",
    "tokens = [words for token_list in token_lists for words in token_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Android', 'Google', 'Android', 'OS', 'worldwide']"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unknown_tokens = [token for token in tokens if token not in V]\n",
    "print(len(unknown_tokens))\n",
    "unknown_tokens[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have unknown tokens let's see the predicted tags by the three approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "vanilla_tags = Viterbi(unknown_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Android', 'CONJ'),\n",
       " ('Google', 'CONJ'),\n",
       " ('Android', 'CONJ'),\n",
       " ('OS', 'CONJ'),\n",
       " ('worldwide', 'CONJ'),\n",
       " ('smartphones', 'CONJ'),\n",
       " ('2011', 'CONJ'),\n",
       " ('2013', 'CONJ'),\n",
       " ('Google', 'CONJ'),\n",
       " ('Twitter', 'CONJ')]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vanilla_tags[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vanilla tag is predicting everything as conjunction which is completely wrong. Lets look at Vanilla viterbi with transition probabailties as back off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Android', 'NOUN'),\n",
       " ('Google', 'NOUN'),\n",
       " ('Android', 'NOUN'),\n",
       " ('OS', 'NOUN'),\n",
       " ('worldwide', 'NOUN'),\n",
       " ('smartphones', 'NOUN'),\n",
       " ('2011', 'NOUN'),\n",
       " ('2013', 'NOUN'),\n",
       " ('Google', 'NOUN'),\n",
       " ('Twitter', 'NOUN'),\n",
       " ('2015', 'NOUN'),\n",
       " ('Google', 'NOUN'),\n",
       " ('Twitter', 'NOUN'),\n",
       " ('firehose', 'NOUN'),\n",
       " ('Twitter', 'NOUN'),\n",
       " ('online', 'NOUN'),\n",
       " ('interact', 'NOUN'),\n",
       " ('messages', 'NOUN'),\n",
       " ('tweets', 'NOUN'),\n",
       " ('domineering', 'NOUN'),\n",
       " ('personality', 'NOUN'),\n",
       " ('2018', 'NOUN'),\n",
       " ('FIFA', 'NOUN'),\n",
       " ('Cup', 'NOUN'),\n",
       " ('21st', 'NOUN'),\n",
       " ('FIFA', 'NOUN'),\n",
       " ('Cup', 'NOUN'),\n",
       " ('tournament', 'NOUN'),\n",
       " ('contested', 'NOUN'),\n",
       " ('Cup', 'NOUN'),\n",
       " ('trips', 'NOUN'),\n",
       " ('arriving', 'NOUN'),\n",
       " ('NASA', 'NOUN'),\n",
       " ('invited', 'NOUN'),\n",
       " ('ICESAT-2', 'NOUN'),\n",
       " ('Satellite', 'NOUN')]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transition_viterbi_tags = Viterbi_transition_back(unknown_tokens)\n",
    "transition_viterbi_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transition viterbi is predicting everything as a noun which is better than the previous case but gives several wrong outputs like domineering is predicted as Noun, invited is also predicted as noun."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now Let's try Viterbi with lexical and rule based back off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Android', 'NOUN'),\n",
       " ('Google', 'NOUN'),\n",
       " ('Android', 'NOUN'),\n",
       " ('OS', 'NOUN'),\n",
       " ('worldwide', 'NOUN'),\n",
       " ('smartphones', 'NOUN'),\n",
       " ('2011', 'NUM'),\n",
       " ('2013', 'NUM'),\n",
       " ('Google', 'NOUN'),\n",
       " ('Twitter', 'NOUN'),\n",
       " ('2015', 'NUM'),\n",
       " ('Google', 'NOUN'),\n",
       " ('Twitter', 'NOUN'),\n",
       " ('firehose', 'NOUN'),\n",
       " ('Twitter', 'NOUN'),\n",
       " ('online', 'NOUN'),\n",
       " ('interact', 'NOUN'),\n",
       " ('messages', 'NOUN'),\n",
       " ('tweets', 'NOUN'),\n",
       " ('domineering', 'VERB'),\n",
       " ('personality', 'NOUN'),\n",
       " ('2018', 'NUM'),\n",
       " ('FIFA', 'NOUN'),\n",
       " ('Cup', 'NOUN'),\n",
       " ('21st', 'NOUN'),\n",
       " ('FIFA', 'NOUN'),\n",
       " ('Cup', 'NOUN'),\n",
       " ('tournament', 'NOUN'),\n",
       " ('contested', 'VERB'),\n",
       " ('Cup', 'NOUN'),\n",
       " ('trips', 'NOUN'),\n",
       " ('arriving', 'VERB'),\n",
       " ('NASA', 'NOUN'),\n",
       " ('invited', 'VERB'),\n",
       " ('ICESAT-2', 'NOUN'),\n",
       " ('Satellite', 'NOUN')]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexical_viterbi_tags = Viterbi_lexical_rule_back(unknown_tokens)\n",
    "lexical_viterbi_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List down cases which were incorrectly tagged by original POS tagger and got corrected by your modifications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. contested: tagged as Noun earlier, corrected to VERB\n",
    "2. 2018: tagged as Noun earlier, corrected to NUM\n",
    "3. arriving: tagged as Noun earlier, corrected to VERB"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
